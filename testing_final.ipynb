{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('cleaned_dataset_with_renamed_description.csv')\n",
    "\n",
    "# Remove duplicate rows based on the 'title' column and keep the first occurrence\n",
    "df_unique = df.drop_duplicates(subset='title', keep='first')\n",
    "\n",
    "# Display the number of rows removed\n",
    "num_duplicates = len(df) - len(df_unique)\n",
    "print(f'Number of duplicate rows removed: {num_duplicates}')\n",
    "\n",
    "# Save the DataFrame with duplicates removed to a new CSV file\n",
    "df_unique.to_csv('cleaned_dataset_with_renamed_description.csv', index=False)\n",
    "\n",
    "print('DataFrame with duplicates removed has been saved to \"paraphrased_bookdataset_no_duplicates.csv\"')\n",
    "df = pd.read_csv('cleaned_dataset_with_renamed_description.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52180b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Function to recommend books based on user input\n",
    "def recommend_books(user_input, book_embeddings, df, top_n=10):\n",
    "    # Convert user input to embedding\n",
    "    user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "    \n",
    "    # Calculate cosine similarity between user input and book embeddings\n",
    "    similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "    \n",
    "    # Get indices of top_n most similar books\n",
    "    top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    \n",
    "    # Get the top recommended books\n",
    "    recommended_books = df.iloc[top_indices]\n",
    "    \n",
    "    # Print the top recommended books and their cosine similarity values\n",
    "    print(f\"Top {top_n} recommended books:\")\n",
    "    for idx in range(top_n):\n",
    "        book = recommended_books.iloc[idx]\n",
    "        similarity = similarities[top_indices[idx]]\n",
    "        print(f\"Title: {book['title']}, Author: {book.get('author', 'Unknown')}, Genre: {book.get('genre', 'Unknown')}, Cosine Similarity: {similarity:.4f}\")\n",
    "    \n",
    "    return recommended_books\n",
    "\n",
    "# Get user input\n",
    "user_input = input(\"Please describe the type of book you want to read: \")\n",
    "\n",
    "# Recommend books based on user input\n",
    "recommend_books(user_input, book_embeddings, df, top_n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920df043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test=pd.read_csv('enhanced_test_data_n=2.csv')\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef1a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for n=2\n",
      "Average Accuracy: 0.9535\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=False, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load book data\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=2.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=20):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=2\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece79d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
