{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b2beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp38-cp38-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp38-cp38-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch) (2.6.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch) (3.7.1)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.3.0\n",
      "  Downloading triton-2.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.0/168.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch) (2021.7.0)\n",
      "Collecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:10\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.0)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.15.1\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.28.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.25)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: mpmath, typing-extensions, triton, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, torchvision, torchaudio, sentence-transformers\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.7.0\n",
      "    Uninstalling fsspec-2021.7.0:\n",
      "      Successfully uninstalled fsspec-2021.7.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.12\n",
      "    Uninstalling huggingface-hub-0.0.12:\n",
      "      Successfully uninstalled huggingface-hub-0.0.12\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.2\n",
      "    Uninstalling tokenizers-0.10.2:\n",
      "      Successfully uninstalled tokenizers-0.10.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.9.1\n",
      "    Uninstalling transformers-4.9.1:\n",
      "      Successfully uninstalled transformers-4.9.1\n",
      "Successfully installed fsspec-2024.3.1 huggingface-hub-0.23.0 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 safetensors-0.4.3 sentence-transformers-2.7.0 sympy-1.12 tokenizers-0.19.1 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 transformers-4.40.1 triton-2.3.0 typing-extensions-4.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.8/dist-packages (2.7.0)\n",
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.40.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.11)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchaudio torchvision sentence-transformers\n",
    "!pip install sentence-transformers faiss-gpu  # or faiss-cpu if GPU is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881c655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset class for handling triplet data\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataframe.iloc[idx]\n",
    "        return {\n",
    "            'anchor': data['anchor'],\n",
    "            'positive': data['positive'],\n",
    "            'negative': data['negative']\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Triplet Loss Model definition\n",
    "class TripletLossModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletLossModel, self).__init__()\n",
    "        self.embedding_model = model\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor_emb = self.embedding_model.encode(anchor, convert_to_tensor=True, device=device)\n",
    "        positive_emb = self.embedding_model.encode(positive, convert_to_tensor=True, device=device)\n",
    "        negative_emb = self.embedding_model.encode(negative, convert_to_tensor=True, device=device)\n",
    "        return anchor_emb, positive_emb, negative_emb\n",
    "\n",
    "# Load dataset and prepare DataLoader\n",
    "df_triplets = pd.read_csv(\"triplet_data.csv\")\n",
    "triplet_dataset = TripletDataset(df_triplets)\n",
    "triplet_loader = DataLoader(triplet_dataset, batch_size=10, shuffle=True, num_workers=5)\n",
    "\n",
    "# Model, Loss, and Optimizer setup\n",
    "triplet_model = TripletLossModel().to(device)\n",
    "loss_function = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = optim.Adam(triplet_model.parameters(), lr=0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data for evaluation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=4.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=50):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=4\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b791b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data for evaluation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=4.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=40):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=4\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data for evaluation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=4.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=60):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=4\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3118006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data for evaluation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=4.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=10):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=4\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data for evaluation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=4.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=20):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=4\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6499e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and embed texts using Sentence Transformers\n",
    "def preprocess_and_embed(texts):\n",
    "    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True, device=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load data for evaluation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\").dropna(subset=['title', 'description'])\n",
    "combined_texts = df['title'] + \" \" + df['description']\n",
    "book_embeddings = preprocess_and_embed(combined_texts.tolist())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"enhanced_test_data_n=4.csv\")\n",
    "# Function to evaluate the recommendation system\n",
    "def evaluate_recommendations(test_df, book_embeddings, df, top_n=30):\n",
    "    # Convert the 'Recommended_Books' column from strings to sets of titles\n",
    "    test_df['Recommended_Books'] = test_df['Recommended_Books'].apply(lambda x: set(x.split(', ')))\n",
    "\n",
    "    # Initialize list to store accuracy\n",
    "    accuracy_list = []\n",
    "\n",
    "    # Loop through each row in the test dataframe\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Get the combined description and true recommended books\n",
    "        user_input = row['Combined_Description']\n",
    "        true_books = row['Recommended_Books']\n",
    "\n",
    "        # Get the user's embedding for the given combined description\n",
    "        user_embedding = preprocess_and_embed([user_input])[0]  # Access the first (and only) embedding\n",
    "\n",
    "        # Calculate cosine similarity between the user's embedding and book embeddings\n",
    "        similarities = cosine_similarity([user_embedding], book_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top_n most similar books\n",
    "        top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "\n",
    "        # Get the top recommended books' titles\n",
    "        predicted_books = set(df.iloc[top_indices]['title'])\n",
    "\n",
    "        # Calculate accuracy by checking if true recommended books are present in the top_n predicted books\n",
    "        correct_recommendations = true_books.intersection(predicted_books)\n",
    "        accuracy = len(correct_recommendations) / len(true_books)\n",
    "\n",
    "        # Append accuracy to the list\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy\n",
    "    average_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "    # Print and return the average accuracy\n",
    "    print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
    "    return {\n",
    "        \"Average Accuracy\": average_accuracy,\n",
    "    }\n",
    "\n",
    "print(\"for n=4\")\n",
    "# Evaluate the recommendation system using the test data\n",
    "results = evaluate_recommendations(test_df, book_embeddings, df, top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f528282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27880958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
