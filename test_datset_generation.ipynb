{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a66fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp38-cp38-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m871.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp38-cp38-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch) (2021.7.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m790.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch) (3.7.1)\n",
      "Collecting triton==2.3.0\n",
      "  Downloading triton-2.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.0/168.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch) (2.6.3)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "Successfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0 typing-extensions-4.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='24.0'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchaudio torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aea818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 462kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 16.4kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 710kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 229kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 268M/268M [00:25<00:00, 10.7MB/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test data for n=6 to enhanced_test_data_n=6.csv\n",
      "Saved test data for n=7 to enhanced_test_data_n=7.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model and tokenizer once\n",
    "def load_model_tokenizer():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "tokenizer, model, device = load_model_tokenizer()\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\")\n",
    "df['title'] = df['title'].str.strip().replace(',', ' ', regex=True)\n",
    "df['description'] = df['description'].str.strip()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return normalize(embeddings.numpy())\n",
    "\n",
    "# Generate embeddings\n",
    "texts = (df['title'] + ' ' + df['description']).tolist()\n",
    "book_embeddings = get_embeddings(texts)\n",
    "\n",
    "# Iterate over different values of n (2, 3, 4, 5, 6, and 7)\n",
    "for n in range(6, 8):\n",
    "    ann_model = NearestNeighbors(n_neighbors=n, metric='cosine')\n",
    "    ann_model.fit(book_embeddings)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Loop through each description in the dataset\n",
    "    for idx, description in enumerate(df['description']):\n",
    "        # Get embeddings for the current description\n",
    "        query_embedding = get_embeddings([description])\n",
    "        \n",
    "        # Get nearest neighbors\n",
    "        distances, indices = ann_model.kneighbors(query_embedding)\n",
    "        \n",
    "        # Combine descriptions and get titles of recommended books\n",
    "        combined_description = ' '.join(df.iloc[indices[0]]['description'])\n",
    "        recommended_books = ', '.join(df.iloc[indices[0]]['title'])\n",
    "        \n",
    "        # Append the result to the list of recommendations\n",
    "        recommendations.append({'Combined_Description': combined_description, 'Recommended_Books': recommended_books})\n",
    "    \n",
    "    # Create a DataFrame from recommendations\n",
    "    test_data = pd.DataFrame(recommendations)\n",
    "    \n",
    "    # Save the test data to a CSV file with the value of n in the filename\n",
    "    filename = f'enhanced_test_data_n={n}.csv'\n",
    "    test_data.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f'Saved test data for n={n} to {filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2427360",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model and tokenizer once\n",
    "def load_model_tokenizer():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "tokenizer, model, device = load_model_tokenizer()\n",
    "\n",
    "# Data preparation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\")\n",
    "df['title'] = df['title'].str.strip().replace(',', ' ', regex=True)\n",
    "df['description'] = df['description'].str.strip()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get embeddings\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return normalize(embeddings.numpy())\n",
    "\n",
    "# Generate embeddings\n",
    "texts = (df['title'] + ' ' + df['description']).tolist()\n",
    "book_embeddings = get_embeddings(texts)\n",
    "\n",
    "# Nearest neighbors for recommendations\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "ann_model = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
    "ann_model.fit(book_embeddings)\n",
    "\n",
    "# Recommendation logic\n",
    "recommendations = []\n",
    "for idx, description in enumerate(df['description']):\n",
    "    query_embedding = get_embeddings([description])\n",
    "    distances, indices = ann_model.kneighbors(query_embedding)\n",
    "    combined_description = ' '.join(df.iloc[indices[0]]['description'])\n",
    "    recommended_books = ', '.join(df.iloc[indices[0]]['title'])\n",
    "    recommendations.append({'Combined_Description': combined_description, 'Recommended_Books': recommended_books})\n",
    "\n",
    "# Save results\n",
    "test_data = pd.DataFrame(recommendations)\n",
    "test_data.to_csv('enhanced_test_data_n=3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model and tokenizer once\n",
    "def load_model_tokenizer():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "tokenizer, model, device = load_model_tokenizer()\n",
    "\n",
    "# Data preparation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\")\n",
    "df['title'] = df['title'].str.strip().replace(',', ' ', regex=True)\n",
    "df['description'] = df['description'].str.strip()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get embeddings\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return normalize(embeddings.numpy())\n",
    "\n",
    "# Generate embeddings\n",
    "texts = (df['title'] + ' ' + df['description']).tolist()\n",
    "book_embeddings = get_embeddings(texts)\n",
    "\n",
    "# Nearest neighbors for recommendations\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "ann_model = NearestNeighbors(n_neighbors=4, metric='cosine')\n",
    "ann_model.fit(book_embeddings)\n",
    "\n",
    "# Recommendation logic\n",
    "recommendations = []\n",
    "for idx, description in enumerate(df['description']):\n",
    "    query_embedding = get_embeddings([description])\n",
    "    distances, indices = ann_model.kneighbors(query_embedding)\n",
    "    combined_description = ' '.join(df.iloc[indices[0]]['description'])\n",
    "    recommended_books = ', '.join(df.iloc[indices[0]]['title'])\n",
    "    recommendations.append({'Combined_Description': combined_description, 'Recommended_Books': recommended_books})\n",
    "\n",
    "# Save results\n",
    "test_data = pd.DataFrame(recommendations)\n",
    "test_data.to_csv('enhanced_test_data_n=4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model and tokenizer once\n",
    "def load_model_tokenizer():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "tokenizer, model, device = load_model_tokenizer()\n",
    "\n",
    "# Data preparation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\")\n",
    "df['title'] = df['title'].str.strip().replace(',', ' ', regex=True)\n",
    "df['description'] = df['description'].str.strip()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get embeddings\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return normalize(embeddings.numpy())\n",
    "\n",
    "# Generate embeddings\n",
    "texts = (df['title'] + ' ' + df['description']).tolist()\n",
    "book_embeddings = get_embeddings(texts)\n",
    "\n",
    "# Nearest neighbors for recommendations\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "ann_model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "ann_model.fit(book_embeddings)\n",
    "\n",
    "# Recommendation logic\n",
    "recommendations = []\n",
    "for idx, description in enumerate(df['description']):\n",
    "    query_embedding = get_embeddings([description])\n",
    "    distances, indices = ann_model.kneighbors(query_embedding)\n",
    "    combined_description = ' '.join(df.iloc[indices[0]]['description'])\n",
    "    recommended_books = ', '.join(df.iloc[indices[0]]['title'])\n",
    "    recommendations.append({'Combined_Description': combined_description, 'Recommended_Books': recommended_books})\n",
    "\n",
    "# Save results\n",
    "test_data = pd.DataFrame(recommendations)\n",
    "test_data.to_csv('enhanced_test_data_5.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee943b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model and tokenizer once\n",
    "def load_model_tokenizer():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "tokenizer, model, device = load_model_tokenizer()\n",
    "\n",
    "# Data preparation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\")\n",
    "df['title'] = df['title'].str.strip().replace(',', ' ', regex=True)\n",
    "df['description'] = df['description'].str.strip()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get embeddings\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return normalize(embeddings.numpy())\n",
    "\n",
    "# Generate embeddings\n",
    "texts = (df['title'] + ' ' + df['description']).tolist()\n",
    "book_embeddings = get_embeddings(texts)\n",
    "\n",
    "# Nearest neighbors for recommendations\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "ann_model = NearestNeighbors(n_neighbors=6, metric='cosine')\n",
    "ann_model.fit(book_embeddings)\n",
    "\n",
    "# Recommendation logic\n",
    "recommendations = []\n",
    "for idx, description in enumerate(df['description']):\n",
    "    query_embedding = get_embeddings([description])\n",
    "    distances, indices = ann_model.kneighbors(query_embedding)\n",
    "    combined_description = ' '.join(df.iloc[indices[0]]['description'])\n",
    "    recommended_books = ', '.join(df.iloc[indices[0]]['title'])\n",
    "    recommendations.append({'Combined_Description': combined_description, 'Recommended_Books': recommended_books})\n",
    "\n",
    "# Save results\n",
    "test_data = pd.DataFrame(recommendations)\n",
    "test_data.to_csv('enhanced_test_data_n=6.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model and tokenizer once\n",
    "def load_model_tokenizer():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return tokenizer, model, device\n",
    "\n",
    "tokenizer, model, device = load_model_tokenizer()\n",
    "\n",
    "# Data preparation\n",
    "df = pd.read_csv(\"cleaned_dataset_with_renamed_description.csv\")\n",
    "df['title'] = df['title'].str.strip().replace(',', ' ', regex=True)\n",
    "df['description'] = df['description'].str.strip()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get embeddings\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    return normalize(embeddings.numpy())\n",
    "\n",
    "# Generate embeddings\n",
    "texts = (df['title'] + ' ' + df['description']).tolist()\n",
    "book_embeddings = get_embeddings(texts)\n",
    "\n",
    "# Nearest neighbors for recommendations\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "ann_model = NearestNeighbors(n_neighbors=7, metric='cosine')\n",
    "ann_model.fit(book_embeddings)\n",
    "\n",
    "# Recommendation logic\n",
    "recommendations = []\n",
    "for idx, description in enumerate(df['description']):\n",
    "    query_embedding = get_embeddings([description])\n",
    "    distances, indices = ann_model.kneighbors(query_embedding)\n",
    "    combined_description = ' '.join(df.iloc[indices[0]]['description'])\n",
    "    recommended_books = ', '.join(df.iloc[indices[0]]['title'])\n",
    "    recommendations.append({'Combined_Description': combined_description, 'Recommended_Books': recommended_books})\n",
    "\n",
    "# Save results\n",
    "test_data = pd.DataFrame(recommendations)\n",
    "test_data.to_csv('enhanced_test_data_n=7.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b3a6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combined_Description</th>\n",
       "      <th>Recommended_Books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The book, Gilead, has been eagerly awaited by ...</td>\n",
       "      <td>Gilead, Song of Solomon, C.S. Lewis, Lady on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agatha Christie's final play novelisation is a...</td>\n",
       "      <td>Spider's Web, The Admirable Crichton ; Peter P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The second volume of Stephen Donaldson's accla...</td>\n",
       "      <td>The One Tree, The Fellowship of the Ring, In t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Arena of organized crime and its flas...</td>\n",
       "      <td>Rage of angels, Exit Strategy, The Laws of Our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lewis' study on the nature of love categorized...</td>\n",
       "      <td>The Four Loves, The Problem of Pain, Selected ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Combined_Description  \\\n",
       "0  The book, Gilead, has been eagerly awaited by ...   \n",
       "1  Agatha Christie's final play novelisation is a...   \n",
       "2  The second volume of Stephen Donaldson's accla...   \n",
       "3  The Dark Arena of organized crime and its flas...   \n",
       "4  Lewis' study on the nature of love categorized...   \n",
       "\n",
       "                                   Recommended_Books  \n",
       "0  Gilead, Song of Solomon, C.S. Lewis, Lady on t...  \n",
       "1  Spider's Web, The Admirable Crichton ; Peter P...  \n",
       "2  The One Tree, The Fellowship of the Ring, In t...  \n",
       "3  Rage of angels, Exit Strategy, The Laws of Our...  \n",
       "4  The Four Loves, The Problem of Pain, Selected ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('enhanced_test_data_n=4.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6f825a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The book, Gilead, has been eagerly awaited by ...</td>\n",
       "      <td>The world-renowned writer of Patrick Bateman, ...</td>\n",
       "      <td>Outlines the process of building Web-based app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agatha Christie's final play novelisation is a...</td>\n",
       "      <td>The New York Times and USA TODAY both praise t...</td>\n",
       "      <td>Provides current, comprehensive coverage that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The second volume of Stephen Donaldson's accla...</td>\n",
       "      <td>Tolkien's timeless fantasy, which centers on t...</td>\n",
       "      <td>Contains general instructions for fitting, tai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Arena of organized crime and its flas...</td>\n",
       "      <td>In this stunning sequel to \"Dead I Well May Be...</td>\n",
       "      <td>The Maple Syrup Cookbook 8-Copy Display is ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lewis' study on the nature of love categorized...</td>\n",
       "      <td>The Puritan tradition's character and life wer...</td>\n",
       "      <td>The 1967 edition of the book was reprinted by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              anchor  \\\n",
       "0  The book, Gilead, has been eagerly awaited by ...   \n",
       "1  Agatha Christie's final play novelisation is a...   \n",
       "2  The second volume of Stephen Donaldson's accla...   \n",
       "3  The Dark Arena of organized crime and its flas...   \n",
       "4  Lewis' study on the nature of love categorized...   \n",
       "\n",
       "                                            positive  \\\n",
       "0  The world-renowned writer of Patrick Bateman, ...   \n",
       "1  The New York Times and USA TODAY both praise t...   \n",
       "2  Tolkien's timeless fantasy, which centers on t...   \n",
       "3  In this stunning sequel to \"Dead I Well May Be...   \n",
       "4  The Puritan tradition's character and life wer...   \n",
       "\n",
       "                                            negative  \n",
       "0  Outlines the process of building Web-based app...  \n",
       "1  Provides current, comprehensive coverage that ...  \n",
       "2  Contains general instructions for fitting, tai...  \n",
       "3  The Maple Syrup Cookbook 8-Copy Display is ava...  \n",
       "4  The 1967 edition of the book was reprinted by ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('triplet_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171c6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
